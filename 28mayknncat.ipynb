{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82483f2f",
   "metadata": {},
   "source": [
    "***GENERATED CODE FOR 28mayknncat PIPELINE.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81002a6",
   "metadata": {},
   "source": [
    "***DON'T EDIT THIS CODE.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa885be",
   "metadata": {},
   "source": [
    "***CONNECTOR FUNCTIONS TO READ DATA.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "class HDFSConnector:\n",
    "\n",
    "    def fetch(spark, config):\n",
    "        ################### INPUT HADOOP HOST PORT TO CONNECT WITH ###############################\n",
    "        hdfs_server = str(os.environ['HDFS_SERVER'])\n",
    "        hdfs_port = int(os.environ['HDFS_PORT'])\n",
    "        df = spark.read.options(header='true', inferschema='true').csv(\n",
    "            f\"hdfs://{hdfs_server}:{hdfs_port}{eval(config)['url']}\", header='true')\n",
    "        display(df.limit(2).toPandas())\n",
    "        return df\n",
    "\n",
    "    def put(df, spark, config):\n",
    "        return df.write.format('csv').options(header='true' if eval(config)[\"is_header\"] == \"Use Header Line\" else 'false',\n",
    "                                              delimiter=eval(config)[\"delimiter\"]).save((\"%s %s\") % (datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")+\"_\", eval(config)['url']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846a63a3",
   "metadata": {},
   "source": [
    "***OPERATION FUNCTIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d032c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from dask.dataframe import from_pandas\n",
    "import json\n",
    "\n",
    "\n",
    "def replaceValues(df, functionsData, applyOn):\n",
    "    for columnData in applyOn:\n",
    "        for functionData in functionsData:\n",
    "            if functionData['replaceType'] == 'value':\n",
    "                if functionData['replaceValueType'] == 'min':\n",
    "                    minValue = df[columnData['columnName']].min().compute()\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].replace(\n",
    "                        toReplace, minValue)\n",
    "                elif functionData['replaceValueType'] == 'max':\n",
    "                    maxValue = df[columnData['columnName']].max().compute()\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].replace(\n",
    "                        toReplace, maxValue)\n",
    "                else:\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].replace(\n",
    "                        toReplace, functionData['ReplaceWith'])\n",
    "            elif functionData['replaceType'] == 'none':\n",
    "                if functionData['replaceValueType'] == 'min':\n",
    "                    minValue = df[columnData['columnName']].min().compute()\n",
    "                    df[columnData['columnName']\n",
    "                       ] = df[columnData['columnName']].replace(\"\", minValue)\n",
    "                    df[columnData['columnName']\n",
    "                       ] = df[columnData['columnName']].fillna(minValue)\n",
    "                elif functionData['replaceValueType'] == 'max':\n",
    "                    maxValue = df[columnData['columnName']].max().compute()\n",
    "                    df[columnData['columnName']\n",
    "                       ] = df[columnData['columnName']].replace(\"\", maxValue)\n",
    "                    df[columnData['columnName']\n",
    "                       ] = df[columnData['columnName']].fillna(maxValue)\n",
    "                else:\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].replace(\n",
    "                        \"\", functionData['ReplaceWith'])\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].fillna(\n",
    "                        functionData['ReplaceWith'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def runDataCleansing(sparkDf, spark, config):\n",
    "    configObj = json.loads(config)\n",
    "    sparkDf.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "    df = from_pandas((sparkDf.toPandas()), npartitions=5)\n",
    "    functionList = configObj['functionsApplied']\n",
    "    Data_Cleansing_Methods = {\"replaceBy\": replaceValues,\n",
    "                              \"formula\": calculateFormula,\n",
    "                              \"aggregate\": aggregation,\n",
    "                              \"converttostringtype\": changeToString,\n",
    "                              \"editname\": renameColumns}\n",
    "    for function in functionList:\n",
    "        function['functionName']\n",
    "        df = Data_Cleansing_Methods[function['functionName']](df, function['functionsData'],\n",
    "                                                              function['applyOn'])\n",
    "    sparkDf = spark.createDataFrame(df.compute())\n",
    "\n",
    "    display(sparkDf.limit(2).toPandas())\n",
    "    return sparkDf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d50ac8",
   "metadata": {},
   "source": [
    "***CONNECTOR FUNCTIONS TO WRITE DATA.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c66318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import datetime\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "class NumtraConnector:\n",
    "\n",
    "    def put(inStages, inStagesData, stageId, spark, config):\n",
    "        path = eval(config)['server_url']\n",
    "        baseType = eval(config)['baseType']\n",
    "        results_url = eval(config)['results_url']\n",
    "        server = eval(config)['server']\n",
    "        originalfile = eval(config)['orignalKey']\n",
    "        eval(config)['pathOnly']\n",
    "        filename = eval(config)['filename']\n",
    "        eval(config)['ser']\n",
    "        eval(config)['user']\n",
    "        eval(config)['password']\n",
    "        eval(config)['authSource']\n",
    "        eval(config)['user_id']\n",
    "        eval(config)['parent_id']\n",
    "        eval(config)['project_id']\n",
    "        time = str(int(datetime.datetime.now().timestamp()))\n",
    "\n",
    "        inStagesData[inStages[0]]\n",
    "\n",
    "        print(path)\n",
    "        print(baseType)\n",
    "        print(results_url)\n",
    "        print(server)\n",
    "        print(originalfile)\n",
    "        print(filename)\n",
    "\n",
    "        args = {\n",
    "            'url': path,\n",
    "            'baseType': baseType,\n",
    "            'originalfile': originalfile,\n",
    "            'filename': time + filename\n",
    "        }\n",
    "\n",
    "        response = requests.post(results_url, args)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0003a0e8",
   "metadata": {},
   "source": [
    "***READING DATAFRAME***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CREATE SPARK SESSION ############################ ENTER YOUR SPARK MASTER IP AND PORT TO CONNECT TO SERVER ################\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[1]').getOrCreate()\n",
    "#%run 28mayknncatHooks.ipynb\n",
    "try:\n",
    "\t#sourcePreExecutionHook()\n",
    "\n",
    "\tpatientchargenrrag = HDFSConnector.fetch(spark, \"{'url': '/FileStore/platform/testdata/1716890915228_Patient_chargesN.csv', 'filename': 'Patient_chargesN.csv', 'delimiter': ',', 'file_type': 'Delimeted', 'dbfs_token': '', 'dbfs_domain': '', 'FilePath': '/DataPipelineTest/Patient_chargesN.csv', 'viewFileName': 'Patient_chargesN.csv', 'is_header': 'Use Header Line', 'baseType': 'hdfs', 'server_url': '/nexusMax/NexusMaxPlatform/uploads/platform/', 'results_url': 'http://dnm.bfirst.ai:44040/api/read/hdfs'}\")\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n",
    "#spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7109c103",
   "metadata": {},
   "source": [
    "***PERFORMING OPERATIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run 28mayknncatHooks.ipynb\n",
    "try:\n",
    "\t#operationPreExecutionHook()\n",
    "\n",
    "datapreparation = runDataCleansing(patientchargenrrag,spark,json.dumps( {\"url\": \"/FileStore/platform/testdata/1716890915228_Patient_chargesN.csv\", \"source_attributes\": {}, \"DataPrepFile\": \"/FileStore/platform/testdata/1716890915228_Patient_chargesN.csv\", \"data_source\": \"platfiles\", \"startListenerOnly\": 1, \"dateColumnNames\": [], \"FilePath\": \"/FileStore/platform/extra/6655ad2f89e855664e5585e21716892635/0part.csv\", \"requestRatio\": 0.0, \"totalRows\": 200, \"BasicStats\": {\"missingValues\": 0.0, \"numberOfColumns\": 8, \"numberOfRows\": 200, \"duplicateRowCount\": 0, \"stats\": [{\"column\": \"age\", \"alias\": \"age\", \"generated\": 0, \"type\": \"numeric\", \"max\": 64, \"min\": 18, \"mean\": 38.12, \"missing\": 0.0, \"stddev\": 14.46, \"outliers\": [], \"validation\": []}, {\"column\": \"sex\", \"alias\": \"sex\", \"generated\": 0, \"type\": \"String\", \"max\": \"male\", \"min\": \"female\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\", \"outliers\": [], \"validation\": []}, {\"column\": \"bmi\", \"alias\": \"bmi\", \"generated\": 0, \"type\": \"real\", \"max\": 49.06, \"min\": 15.96, \"mean\": 30.582875000000005, \"missing\": 0.0, \"stddev\": 5.62, \"outliers\": [49.06, 15.96], \"validation\": []}, {\"column\": \"children\", \"alias\": \"children\", \"generated\": 0, \"type\": \"numeric\", \"max\": 5, \"min\": 0, \"mean\": 1.065, \"missing\": 0.0, \"stddev\": 1.23, \"outliers\": [5, 5, 5], \"validation\": []}, {\"column\": \"smoker\", \"alias\": \"smoker\", \"generated\": 0, \"type\": \"String\", \"max\": \"yes\", \"min\": \"no\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\", \"outliers\": [], \"validation\": []}, {\"column\": \"region\", \"alias\": \"region\", \"generated\": 0, \"type\": \"String\", \"max\": \"southwest\", \"min\": \"northeast\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\", \"outliers\": [], \"validation\": []}, {\"column\": \"charges\", \"alias\": \"charges\", \"generated\": 0, \"type\": \"real\", \"max\": 51194.55914, \"min\": 1137.011, \"mean\": 13169.288606150001, \"missing\": 0.0, \"stddev\": 12407.46, \"outliers\": [39611.7577, 36837.467, 37701.8768, 38711.0, 35585.576, 51194.55914, 39774.2763, 48173.361, 38709.176, 37742.5757, 47496.49445, 34303.1672, 37165.1638, 39836.519, 43578.9394, 47291.055, 47055.5321, 39556.4945, 40720.55105, 36950.2567, 36149.4835, 48824.45, 43753.33705], \"validation\": []}, {\"column\": \"Gender\", \"alias\": \"Gender\", \"generated\": 1, \"type\": \"String\", \"max\": \"male\", \"min\": \"female\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\", \"outliers\": [], \"validation\": []}]}, \"predictionPowerScore\": [{\"Gender\": 1.0, \"age\": 0.0, \"bmi\": 0.0, \"charges\": 0.3051285449, \"children\": 0.0, \"region\": 0.0, \"sex\": 1.0, \"smoker\": 0.0577042914}, {\"Gender\": 0.0, \"age\": 1.0, \"bmi\": 0.0, \"charges\": 0.531650641, \"children\": 0.0, \"region\": 0.0, \"sex\": 0.0, \"smoker\": 0.0}, {\"Gender\": 0.0, \"age\": 0.0, \"bmi\": 1.0, \"charges\": 0.0, \"children\": 0.0, \"region\": 0.0196018981, \"sex\": 0.0, \"smoker\": 0.0}, {\"Gender\": 0.0, \"age\": 0.0, \"bmi\": 0.0, \"charges\": 1.0, \"children\": 0.0, \"region\": 0.0, \"sex\": 0.0, \"smoker\": 0.3520416244}, {\"Gender\": 0.0, \"age\": 0.0, \"bmi\": 0.0, \"charges\": 0.0, \"children\": 1.0, \"region\": 0.0, \"sex\": 0.0, \"smoker\": 0.0}, {\"Gender\": 0.0, \"age\": 0.0708086154, \"bmi\": 0.1472161185, \"charges\": 0.0792856488, \"children\": 0.0, \"region\": 1.0, \"sex\": 0.0, \"smoker\": 0.0}, {\"Gender\": 1.0, \"age\": 0.0, \"bmi\": 0.0, \"charges\": 0.3051285449, \"children\": 0.0, \"region\": 0.0, \"sex\": 1.0, \"smoker\": 0.0577042914}, {\"Gender\": 0.0, \"age\": 0.0, \"bmi\": 0.0129094639, \"charges\": 0.6759079269, \"children\": 0.0, \"region\": 0.0, \"sex\": 0.0, \"smoker\": 1.0}], \"HasBasicStats\": 1, \"functionsApplied\": [{\"functionName\": \"replaceBy\", \"applyOn\": [{\"columnName\": \"sex\", \"type\": \"String\", \"min\": \"-\", \"max\": \"-\", \"mean\": \"-\"}], \"functionsData\": [{\"replaceType\": \"none\", \"replaceValueCondition\": \"none\", \"toReplace\": \"\", \"asNewColumn\": 1, \"newColumnName\": \"Gender\", \"replaceValueType\": \"byKnn\", \"ReplaceWith\": 3}]}], \"functionChanges\": [{\"columnName\": \"sex\", \"functionName\": \"Replace Outliers\", \"Type\": \"String\", \"Parameters\": [{\"replaceType\": \"none\", \"replaceValueCondition\": \"none\", \"toReplace\": \"\", \"asNewColumn\": 1, \"newColumnName\": \"Gender\", \"replaceValueType\": \"byKnn\", \"ReplaceWith\": 3}]}], \"fileheader\": [{\"field\": \"age\", \"alias\": \"age\", \"generated\": 0, \"position\": 1, \"type\": \"numeric\"}, {\"field\": \"sex\", \"alias\": \"sex\", \"generated\": 0, \"position\": 2, \"type\": \"String\"}, {\"field\": \"bmi\", \"alias\": \"bmi\", \"generated\": 0, \"position\": 3, \"type\": \"real\"}, {\"field\": \"children\", \"alias\": \"children\", \"generated\": 0, \"position\": 4, \"type\": \"numeric\"}, {\"field\": \"smoker\", \"alias\": \"smoker\", \"generated\": 0, \"position\": 5, \"type\": \"String\"}, {\"field\": \"region\", \"alias\": \"region\", \"generated\": 0, \"position\": 6, \"type\": \"String\"}, {\"field\": \"charges\", \"alias\": \"charges\", \"generated\": 0, \"position\": 7, \"type\": \"real\"}, {\"field\": \"Gender\", \"alias\": \"Gender\", \"generated\": 1, \"position\": 8, \"type\": \"String\"}]}))\n",
    "\t#operationPostExecutionHook(datapreparation)\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc7d57",
   "metadata": {},
   "source": [
    "***WRITING DATAFRAME***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run 28mayknncatHooks.ipynb\n",
    "try:\n",
    "\t#sinkPreExecutionHook()\n",
    "\n",
    "\tdatapipelinetestoutput = NumtraConnector.fetch(spark, \"{'samplefile': '/FileStore/platform/sampleData/6655ad1589e855664e5585c7/part-00000-648da899-a2f2-49dc-9b66-e948cd14dfd6-c000.csv', 'samplecount': 200, 'originalcount': 200, 'orignalKey': '/FileStore/platform/testdata/1716890915228_Patient_chargesN.csv', 'pathOnly': '/DataPipelineTest', 'project_id': '65d6eaa27ff4e119ca47d614', 'parent_id': '65d6eaa27ff4e119ca47d614', 'original_schema': [{'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'age', 'alias': 'age', 'type': 'numeric', 'position': '0'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'sex', 'alias': 'sex', 'type': 'String', 'position': '1'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'bmi', 'alias': 'bmi', 'type': 'real', 'position': '2'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'children', 'alias': 'children', 'type': 'numeric', 'position': '3'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'smoker', 'alias': 'smoker', 'type': 'String', 'position': '4'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'region', 'alias': 'region', 'type': 'String', 'position': '5'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'charges', 'alias': 'charges', 'type': 'real', 'position': '6'}], 'actual_schema': [{'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'age', 'alias': 'age', 'type': 'numeric', 'position': '0'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'sex', 'alias': 'sex', 'type': 'String', 'position': '1'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'bmi', 'alias': 'bmi', 'type': 'real', 'position': '2'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'children', 'alias': 'children', 'type': 'numeric', 'position': '3'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'smoker', 'alias': 'smoker', 'type': 'String', 'position': '4'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'region', 'alias': 'region', 'type': 'String', 'position': '5'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'charges', 'alias': 'charges', 'type': 'real', 'position': '6'}], 'server': 'https://dnm.bfirst.ai:443', 'server_url': '/nexusMax/NexusMaxPlatform/uploads/platform/', 'delimiter': ',', 'file_type': 'Delimeted', 'filename': 'KNNCatOp.csv', 'token': '', 'domain': '', 'is_header': 'Use Header Line', 'url': '/FileStore/platform/uploadedSourceFiles/part-00000-01773a5c-a150-4ee8-a2e6-73aa8b00d66f-c000.csv', 'results_url': 'http://dnm.bfirst.ai:44040/api/read/hdfs'}\")\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
